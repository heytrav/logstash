input {
  lumberjack {
    port => 5043
    type => "lumberjack"
    ssl_certificate => "/etc/ssl/etcd/logstash.crt"
    ssl_key => "/etc/ssl/etcd/logstash.key"
  }
}

filter {
  syslog_pri {}

  if [type] == "syslog" {
        grok {
            patterns_dir => "/etc/logstash/patterns"
            match => {
                "message" => "%{TIMESTAMP_ISO8601:syslog_timestamp} %{SYSLOGHOST:syslog_hostname} supervisord:\s%{GREEDYDATA:[@metadata][supervisor_log]}"
            }
        }
        if [@metadata][supervisor_log] {

          grok {
            patterns_dir => "/etc/logstash/patterns"
            match => {
              "[@metadata][supervisor_log]" => "couch\s%{GREEDYDATA:[@metadata][couch_message]}"
            }
            add_tag => ["couchdb"]
          }
          grok {
            patterns_dir => "/etc/logstash/patterns"
            match => {
              "[@metadata][supervisor_log]" => "kyototycoon\s%{GREEDYDATA:[@metadata][kyoto_message]}"
            }
            add_tag => ["kyototycoon"]
          }
          if ("couchdb" in [tags]) {
            grok {
                patterns_dir => "/etc/logstash/patterns"
                match => {
                    "[@metadata][couch_message]" => "\[%{LOGLEVEL:loglevel}\]\s\[<%{DATA:elapsed}>\]\s%{IPORHOST:request_host}\s-\s-\s%{WORD:request_method}\s%{PATH:request_path}\s%{NONNEGINT:status}"
                }
              remove_tag => ["_grokparsefailure"]
            }
          } else if ("kyototycoon" in [tags]) {
            grok {
                patterns_dir => "/etc/logstash/patterns"
                match => {
                    "[@metadata][kyoto_message]" => "%{TIMESTAMP_ISO8601}:\s\[%{DATA:kyoto_type}\]:\s%{GREEDYDATA:kyoto_log}"
                }
              remove_tag => ["_grokparsefailure"]
            }
          } else {
            grok {
                patterns_dir => "/etc/logstash/patterns"
                match => {
                    "[@metadata][supervisor_log]" => "%{DATA:supervisor_program} %{DATA:syslog_program}:line %{NONNEGINT:linenumber}(?:\[%{POSINT:syslog_pid}\])?(?:\s\[%{LOGLEVEL:loglevel}\])?: (?<module>[^\s]+) - %{GREEDYDATA:[@metadata][program_output]}"
                }
            }
            if [@metadata][program_output] {
              grok {
                patterns_dir => "/etc/logstash/patterns"
                match => {
                    "[@metadata][program_output]" => '%{IPORHOST:request_host}\s-\s-\s\[%{FLASKDATE:flaskdate}\]\s\"%{WORD:request_method}\s+%{PATH:request_path}\sHTTP\/%{NUMBER:http_version}\"\s%{NONNEGINT:status}%{GREEDYDATA}'
                }
                add_field => [ "received_at", "%{@timestamp}" ]
                add_field => [ "received_from", "%{host}" ]
                remove_tag => ["_grokparsefailure"]
                add_tag => ["httpRequest"]
              }
              if !("httpRequest" in [tags]) {
                grok {
                    patterns_dir => "/etc/logstash/patterns"
                    match => {
                        "[@metadata][program_output]" => "STARTRABBIT:%{DATA:rabbit_queried};CORRELATION_ID:%{UUID:[@metadata][correlation_id]}"
                    }
                    add_tag => ["rabbitStarted", "elapsedTest"]
                }
                
                if !("rabbitStarted" in [tags]) {
                    grok {
                      patterns_dir => "/etc/logstash/patterns"
                      match => {
                          "[@metadata][program_output]" => "STOPRABBIT:%{DATA:rabbit_queried};CORRELATION_ID:%{UUID:[@metadata][correlation_id]}"
                      }
                      add_tag => ["rabbitFinished", "elapsedTest"]
                      remove_field => ["queue"]
                      remove_tag => ["_grokparsefailure"]
                    }
                }
              }
            }
          }
        }

    date {
        match => [ "syslog_timestamp", "MMM  d HH:mm:ss", "MMM dd HH:mm:ss", "ISO8601" ]
    }
    elapsed {
        start_tag => "rabbitStarted"
        end_tag => "rabbitFinished"
        unique_id_field => "[@metadata][correlation_id]"
        timeout => 60
    }
  }
}

output {
  elasticsearch {
    host => "localhost"
    protocol => "transport"
  }
  stdout { codec => json }
}
