input {
  lumberjack {
    port => LUMBERJACK_SERVICE_PORT
    type => "lumberjack"
    ssl_certificate => "/data/logstash/certs/logstash-forwarder.crt"
    ssl_key => "/data/logstash/private/logstash-forwarder.key"
  }
}

input{
    collectd {}
}

filter {
  if [type] == "syslog" {
        grok {
            patterns_dir => "/etc/logstash/patterns"
            match => {
                "message" => "%{TIMESTAMP_ISO8601:syslog_timestamp} %{SYSLOGHOST:syslog_hostname} supervisord: %{DATA:supervisor_program} %{DATA:syslog_program}:line %{NONNEGINT:linenumber}(?:\[%{POSINT:syslog_pid}\])?(?:\s\[%{LOGLEVEL:loglevel}\])?: (?<module>[^\s]+) - STARTRABBIT:%{DATA:queue};CORRELATION_ID:%{UUID:correlation_id}"
            }
            add_tag => ["rabbitStarted", "elapsedTest"]
            add_field => ["rabbit_queried", "%{queue}"]
            remove_field => ["queue"]
        }

        if !("rabbitStarted" in [tags]) {
            grok {
            patterns_dir => "/etc/logstash/patterns"
            match => {
                "message" => "%{TIMESTAMP_ISO8601:syslog_timestamp} %{SYSLOGHOST:syslog_hostname} supervisord: %{DATA:supervisor_program} %{DATA:syslog_program}:line %{NONNEGINT:linenumber}(?:\[%{POSINT:syslog_pid}\])?(?:\s\[%{LOGLEVEL:loglevel}\])?: (?<module>[^\s]+) - STOPRABBIT:%{DATA:queue};CORRELATION_ID:%{UUID:correlation_id}"
            }
            add_tag => ["rabbitFinished", "elapsedTest"]
            add_field => ["rabbit_responded", "%{queue}"]
            remove_field => ["queue"]
            remove_tag => ["_grokparsefailure"]
            }
        }
        if !("elapsedTest" in [tags]) {

            grok {
            patterns_dir => "/etc/logstash/patterns"
            match => {
                "message" => '%{TIMESTAMP_ISO8601:syslog_timestamp} %{SYSLOGHOST:syslog_hostname} supervisord: %{DATA:supervisor_program} %{DATA:syslog_program}:line %{NONNEGINT:linenumber}(?:\[%{POSINT:syslog_pid}\])?(?:\s\[%{LOGLEVEL:loglevel}\])?: (?<module>[^\s]+) - %{IPORHOST:request_host}\s-\s-\s\[%{FLASKDATE:flaskdate}\]\s\"%{WORD:request_method}\s+%{PATH:request_path}\sHTTP\/%{NUMBER:http_version}\"\s%{NONNEGINT:status}%{GREEDYDATA}'
            }
            add_field => [ "received_at", "%{@timestamp}" ]
            add_field => [ "received_from", "%{host}" ]
            remove_tag => ["_grokparsefailure"]
            add_tag => ["httpRequest"]
            }
            if !("httpRequest" in [tags]) {
                grok {
                patterns_dir => "/etc/logstash/patterns"
                match => {
                    "message" => "%{TIMESTAMP_ISO8601:syslog_timestamp} %{SYSLOGHOST:syslog_hostname} supervisord: %{DATA:supervisor_program} %{DATA:syslog_program}:line %{NONNEGINT:linenumber}(?:\[%{POSINT:syslog_pid}\])?(?:\s\[%{LOGLEVEL:loglevel}\])?: (?<module>[^\s]+) - %{GREEDYDATA:syslog_message}"
                }
                add_field => [ "received_at", "%{@timestamp}" ]
                add_field => [ "received_from", "%{host}" ]
                remove_tag => ["_grokparsefailure"]
                }
            }
            syslog_pri { }
        }
        date {
            match => [ "syslog_timestamp", "MMM  d HH:mm:ss", "MMM dd HH:mm:ss", "ISO8601" ]
        }
    elapsed {
        start_tag => "rabbitStarted"
        end_tag => "rabbitFinished"
        unique_id_field => "correlation_id"
        timeout => 60
    }
  }
}

output {
  elasticsearch_http {
    host => "localhost"
    port => "9300"
    }
}
